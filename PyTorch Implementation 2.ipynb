{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c045968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow dependencies \n",
    "import logging\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#import tensorflow_datasets as tfds ==> not required cause building custom datatset\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "469fd838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bde8c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = hub.KerasLayer(\"MuRIL_preprocess_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d62fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = hub.KerasLayer(\"MuRIL_1\", trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daed5bb9",
   "metadata": {},
   "source": [
    "# Encoder Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0975f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"This is a text\", \"This is another text\"]\n",
    "list_tensor = tf.convert_to_tensor(sentences)\n",
    "\n",
    "output = encoder(preprocessor(list_tensor))\n",
    "\n",
    "print(output[\"sequence_output\"])\n",
    "print(output[\"sequence_output\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76149ad8",
   "metadata": {},
   "source": [
    "# Decoder Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e58eb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33d1c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = preprocessor(list_tensor)['input_word_ids']\n",
    "\n",
    "\n",
    "for i in range(tokens.shape[0]):\n",
    "    token = np.array(tokens[i])\n",
    "    token_list = []\n",
    "    for _ in token:\n",
    "        if _ != 0:\n",
    "            token_list.append(_)\n",
    "    \n",
    "    input_tokens = token_list[:-1]\n",
    "    input_labels = token_list[1:]\n",
    "    \n",
    "    for j in range(128):\n",
    "        input_tokens.append(0)\n",
    "        input_labels.append(0)\n",
    "        \n",
    "    input_labels = tf.ragged.constant([input_labels[:128]]).to_tensor()\n",
    "    input_tokens = tf.ragged.constant([input_tokens[:128]]).to_tensor()\n",
    "    \n",
    "    if i == 0:\n",
    "        decoder_label = input_labels\n",
    "        decoder_input = input_tokens\n",
    "        \n",
    "    else:\n",
    "        decoder_label = tf.concat([decoder_label, input_labels], axis = 0)\n",
    "        decoder_input = tf.concat([decoder_input, input_tokens], axis = 0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da55c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41122273",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "116a61a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder():\n",
    "    def __init__(self):\n",
    "        self.encoder = hub.KerasLayer(\"MuRIL_1\", trainable=True)\n",
    "        self.preprocessor = hub.KerasLayer(\"MuRIL_preprocess_1\")\n",
    "        \n",
    "    def generate_tokens(self, sentences):\n",
    "        #list_tensor = tf.convert_to_tensor(sentences)\n",
    "        #processor_output = self.preprocessor(list_tensor)\n",
    "        processor_output = self.preprocessor(tf.constant([sentences]))\n",
    "        encoder_output = self.encoder(processor_output)\n",
    "        \n",
    "        return encoder_output[\"sequence_output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ee255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['This is a text', \n",
    "             'This is a text in hindi', \n",
    "             'This is a text in hindi']\n",
    "\n",
    "encoder = Encoder()\n",
    "encoder_output = encoder.generate_tokens(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68b1961",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1a96c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLabelsInputs():\n",
    "    def __init__(self):\n",
    "        self.preprocessor = hub.KerasLayer(\"MuRIL_preprocess_1\")\n",
    "        \n",
    "    def generate_labels_inputs(self, sentences):\n",
    "        #list_tensor = tf.convert_to_tensor(sentences)\n",
    "        #tokens = preprocessor(list_tensor)['input_word_ids']\n",
    "        \n",
    "        tokens = self.preprocessor(tf.constant([sentences]))['input_word_ids']\n",
    "        \n",
    "        for i in range(tokens.shape[0]):\n",
    "            token = np.array(tokens[i])\n",
    "            token_list = []\n",
    "            for _ in token:\n",
    "                if _ != 0:\n",
    "                    token_list.append(_)\n",
    "\n",
    "            input_tokens = token_list[:-1]\n",
    "            input_labels = token_list[1:]\n",
    "\n",
    "            for j in range(128):\n",
    "                input_tokens.append(0)\n",
    "                input_labels.append(0)\n",
    "\n",
    "            input_labels = tf.ragged.constant([input_labels[:128]]).to_tensor()\n",
    "            input_tokens = tf.ragged.constant([input_tokens[:128]]).to_tensor()\n",
    "\n",
    "            if i == 0:\n",
    "                decoder_label = input_labels\n",
    "                decoder_input = input_tokens\n",
    "\n",
    "            else:\n",
    "                decoder_label = tf.concat([decoder_label, input_labels], axis = 0)\n",
    "                decoder_input = tf.concat([decoder_input, input_tokens], axis = 0)\n",
    "                \n",
    "        \n",
    "        return decoder_label, decoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d6dd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['This is a text', \n",
    "             'This is a text in hindi', \n",
    "             'This is a text in hindi']\n",
    "\n",
    "decoder_labels_inputs = DecoderLabelsInputs()\n",
    "decoder_label, decoder_input = decoder_labels_inputs.generate_labels_inputs(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefbcb32",
   "metadata": {},
   "source": [
    "# Attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cac42b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "    depth = depth/2\n",
    "    positions = np.arange(length)[:, np.newaxis]\n",
    "    depths = np.arange(depth)[np.newaxis, :]/depth\n",
    "    \n",
    "    angle_rates = 1 / (10000**depths)\n",
    "    angle_rads = positions * angle_rates\n",
    "    \n",
    "    pos_encoding = np.concatenate(\n",
    "        [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "        axis = -1)\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e9a9716",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero = True)\n",
    "        self.pos_encoding = positional_encoding(length = 2048, depth = d_model)\n",
    "        \n",
    "    def compute_mask(self, *args, **kwargs):\n",
    "        return self.embedding.compute_mask(*args, **kwargs)\n",
    "    \n",
    "    def call(self, x):\n",
    "        length = tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e82d2640",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(num_heads=8, key_dim=768)\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b57c72af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalMask():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def _compute_causal_mask(self, query, value=None):    \n",
    "        q_seq_length = tf.shape(query)[1]\n",
    "        v_seq_length = q_seq_length if value is None else tf.shape(value)[1]\n",
    "        return tf.linalg.band_part(tf.ones((1, q_seq_length, v_seq_length), tf.bool), -1, 0)\n",
    "\n",
    "    def _compute_attention_mask(self, query, value, key=None, attention_mask=None, use_causal_mask=False):\n",
    "        query_mask = getattr(query, \"_keras_mask\", None)\n",
    "        value_mask = getattr(value, \"_keras_mask\", None)\n",
    "        key_mask = getattr(key, \"_keras_mask\", None)\n",
    "        auto_mask = None\n",
    "        if query_mask is not None:\n",
    "            query_mask = tf.cast(query_mask, tf.bool)  # defensive casting\n",
    "            # B = batch size, T = max query length\n",
    "            auto_mask = query_mask[:, :, tf.newaxis]  # shape is [B, T, 1]\n",
    "        if value_mask is not None:\n",
    "            value_mask = tf.cast(value_mask, tf.bool)  # defensive casting\n",
    "            # B = batch size, S == max value length\n",
    "            mask = value_mask[:, tf.newaxis, :]  # shape is [B, 1, S]\n",
    "            auto_mask = mask if auto_mask is None else auto_mask & mask\n",
    "        if key_mask is not None:\n",
    "            key_mask = tf.cast(key_mask, tf.bool)  # defensive casting\n",
    "            # B == batch size, S == max key length == max value length\n",
    "            mask = key_mask[:, tf.newaxis, :]  # shape is [B, 1, S]\n",
    "            auto_mask = mask if auto_mask is None else auto_mask & mask\n",
    "        if use_causal_mask:\n",
    "            # the shape of the causal mask is [1, T, S]\n",
    "            mask = self._compute_causal_mask(query, value)\n",
    "            auto_mask = mask if auto_mask is None else auto_mask & mask\n",
    "        if auto_mask is not None:\n",
    "            # merge attention_mask & automatic mask, to shape [B, T, S]\n",
    "            attention_mask = (\n",
    "                auto_mask\n",
    "                if attention_mask is None\n",
    "                else tf.cast(attention_mask, bool) & auto_mask\n",
    "            )\n",
    "        return attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbf97618",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(BaseAttention, CausalMask):\n",
    "    def call(self, x, context):\n",
    "        mask = CausalMask()\n",
    "        mask = mask._compute_attention_mask(query=x, \n",
    "                                        value=context, \n",
    "                                        key=context, \n",
    "                                        use_causal_mask=False)\n",
    "        \n",
    "        attn_output = self.mha(query = x,\n",
    "                                key = context,\n",
    "                                value = context,\n",
    "                                attention_mask = mask)\n",
    "        \n",
    "        #self.last_attn_scores = attn_scores\n",
    "        \n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7594552",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttention(BaseAttention):\n",
    "    def call(self, x):\n",
    "        mask = CausalMask()\n",
    "        mask = mask._compute_attention_mask(query=x, \n",
    "                                        value=x, \n",
    "                                        key=x, \n",
    "                                        use_causal_mask=True)\n",
    "        \n",
    "        attn_output = self.mha(query = x,\n",
    "                                key = x,\n",
    "                                value = x,\n",
    "                                attention_mask = mask)\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33096bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model = 768, dff = 2048, dropout_rate = 0.1):\n",
    "        super().__init__()\n",
    "        self.seq = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(dff, activation = 'relu'),\n",
    "            tf.keras.layers.Dense(d_model),\n",
    "            tf.keras.layers.Dropout(dropout_rate)\n",
    "        ])\n",
    "        \n",
    "        self.add = tf.keras.layers.Add()\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.add([x, self.seq(x)])\n",
    "        x = self.layer_norm(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3acd8e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):      \n",
    "    def __init__(self):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.causal_self_attention = CausalAttention()\n",
    "        self.cross_attention = CrossAttention()\n",
    "        self.ffn = FeedForward()\n",
    "        \n",
    "    \n",
    "    def call(self, x, context):\n",
    "        x = self.causal_self_attention(x = x)\n",
    "        x = self.cross_attention(x = x, context = context)\n",
    "        \n",
    "        x = self.ffn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbf203c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.pos_embedding = PositionalEmbedding(vocab_size = 197285, \n",
    "                                                 d_model = 768)\n",
    "        self.dropout = tf.keras.layers.Dropout(0.1)\n",
    "        \n",
    "        self.dec_layers = [\n",
    "            DecoderLayer()\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "        \n",
    "    def call(self, x, context):\n",
    "        x = self.pos_embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x, context)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8a80870",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        self.decoder = Decoder(num_layers = 4)\n",
    "        self.final_layer = tf.keras.layers.Dense(197285)\n",
    "    \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        encoder_output, decoder_input = inputs\n",
    " \n",
    "        decoder_output = self.decoder(decoder_input, encoder_output)\n",
    "        \n",
    "        logits = self.final_layer(decoder_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "158474c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.d_model = 768\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "        \n",
    "        self.warmup_steps = 4000\n",
    "        \n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, dtype = tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46af8477",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, \n",
    "                                     beta_1 = 0.9,\n",
    "                                     beta_2 = 0.98,\n",
    "                                     epsilon = 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "787775f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(decoder_label, pred_label):\n",
    "    mask = decoder_label != 0\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                                            from_logits = True,\n",
    "                                            reduction = 'none')\n",
    "    \n",
    "    loss = loss_object(decoder_label, pred_label)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype = loss.dtype)\n",
    "    \n",
    "    loss *= mask\n",
    "    \n",
    "    loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76b43408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_accuracy(decoder_label, pred_label):\n",
    "    pred_label = tf.argmax(pred_label, axis = 2)\n",
    "    decoder_label = tf.cast(decoder_label, pred_label.dtype)\n",
    "    \n",
    "    match = decoder_label == pred_label\n",
    "    mask = decoder_label != 0\n",
    "    \n",
    "    match = match & mask\n",
    "    \n",
    "    match = tf.cast(match, dtype = tf.float32)\n",
    "    mask = tf.cast(mask, dtype = tf.float32)\n",
    "    \n",
    "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c4a68f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_transformer_decoder = TransformerDecoder()\n",
    "sample_transformer_decoder.compile(loss = masked_loss,\n",
    "                          optimizer = optimizer,\n",
    "                          metrics = [masked_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cd74ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_transformer_decoder.fit(x = (encoder_output, decoder_input),\n",
    "                               y = decoder_label,\n",
    "                               epochs = 5,\n",
    "                               verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1361ca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensure internet connectivity\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "english_sent = []\n",
    "hindi_sent = []\n",
    "\n",
    "try:\n",
    "    dataset = load_dataset(\"cfilt/iitb-english-hindi\")\n",
    "    list_dataset = dataset['train']['translation']\n",
    "\n",
    "    for i in tqdm(range(len(list_dataset))):\n",
    "        english_sent.append(list_dataset[i]['en'])\n",
    "        hindi_sent.append(list_dataset[i]['hi'])\n",
    "\n",
    "except ConnectionError:\n",
    "    english_sent.append('This is an english sent')\n",
    "    hindi_sent.append('This is a hindi text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab321268",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(english_sent[10000])\n",
    "print(hindi_sent[10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea6ff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(english_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9d1be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_sent = english_sent[:1000]\n",
    "hindi_sent = hindi_sent[:1000]\n",
    "\n",
    "encoder = Encoder()\n",
    "encoder_output = encoder.generate_tokens(hindi_sent)\n",
    "\n",
    "decoder_labels_inputs = DecoderLabelsInputs()\n",
    "decoder_label, decoder_input = decoder_labels_inputs.generate_labels_inputs(english_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6077a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_transformer_decoder.fit(x = (encoder_output, decoder_input),\n",
    "                               y = decoder_label,\n",
    "                               epochs = 5,\n",
    "                               verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12e48f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4191494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stories():\n",
    "    full_text_hindi = []\n",
    "    full_text_english = []\n",
    "    \n",
    "    #process hindi\n",
    "    for i in range(1,6):\n",
    "        file_name = \"hindi_stories/hindi/S\" + str(i) + \"-HINDI.docx\"\n",
    "        doc = docx.Document(file_name)\n",
    "        for para in doc.paragraphs:\n",
    "            full_text_hindi.append(para.text)\n",
    "            \n",
    "    #process english\n",
    "    for i in range(1,6):\n",
    "        file_name = \"hindi_stories/english/S\" + str(i) + \"-ENG.docx\"\n",
    "        doc = docx.Document(file_name)\n",
    "        for para in doc.paragraphs:\n",
    "            full_text_english.append(para.text)\n",
    "    \n",
    "    \n",
    "    return full_text_hindi, full_text_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "439f48fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_text, english_text = process_stories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d6e737",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(hindi_text))\n",
    "print(len(english_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d631eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_sent = english_text\n",
    "hindi_sent = hindi_text\n",
    "\n",
    "encoder = Encoder()\n",
    "encoder_output = encoder.generate_tokens(hindi_sent)\n",
    "\n",
    "decoder_labels_inputs = DecoderLabelsInputs()\n",
    "decoder_label, decoder_input = decoder_labels_inputs.generate_labels_inputs(english_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "894821d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 6149/6149 [14:33<00:00,  7.04it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "encoder_output_list = []\n",
    "decoder_input_list = []\n",
    "decoder_label_list = []\n",
    "\n",
    "english_sent = english_text\n",
    "hindi_sent = hindi_text\n",
    "\n",
    "encoder = Encoder()\n",
    "decoder_labels_inputs = DecoderLabelsInputs()\n",
    "\n",
    "for i in tqdm(range(len(hindi_sent))):\n",
    "    encoder_output = encoder.generate_tokens(hindi_sent[i])\n",
    "    encoder_output_list.append(encoder_output)\n",
    "    \n",
    "    decoder_label, decoder_input = decoder_labels_inputs.generate_labels_inputs(english_sent[i])\n",
    "    decoder_input_list.append(decoder_input)\n",
    "    decoder_label_list.append(decoder_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa23cd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 6147/6147 [09:17<00:00, 11.03it/s]\n"
     ]
    }
   ],
   "source": [
    "tf_1 = encoder_output_list[0]\n",
    "tf_2 = encoder_output_list[1]\n",
    "\n",
    "encoder_output = tf.concat([tf_1, tf_2], axis = 0)\n",
    "\n",
    "for i in tqdm(range(len(encoder_output_list[2:]))):\n",
    "    tf_2 = encoder_output_list[i]\n",
    "    encoder_output = tf.concat([encoder_output, tf_2], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51d59567",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 6147/6147 [00:00<00:00, 11946.85it/s]\n"
     ]
    }
   ],
   "source": [
    "tf_1 = decoder_input_list[0]\n",
    "tf_2 = decoder_input_list[1]\n",
    "\n",
    "decoder_input = tf.concat([tf_1, tf_2], axis = 0)\n",
    "\n",
    "for i in tqdm(range(len(decoder_input_list[2:]))):\n",
    "    tf_2 = decoder_input_list[i]\n",
    "    decoder_input = tf.concat([decoder_input, tf_2], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0fa60cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 6147/6147 [00:00<00:00, 12111.75it/s]\n"
     ]
    }
   ],
   "source": [
    "tf_1 = decoder_label_list[0]\n",
    "tf_2 = decoder_label_list[1]\n",
    "\n",
    "decoder_label = tf.concat([tf_1, tf_2], axis = 0)\n",
    "\n",
    "for i in tqdm(range(len(decoder_label_list[2:]))):\n",
    "    tf_2 = decoder_label_list[i]\n",
    "    decoder_label = tf.concat([decoder_label, tf_2], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1eee797d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "193/193 [==============================] - 10389s 54s/step - loss: 1.2680 - masked_accuracy: 0.0578\n",
      "Epoch 2/20\n",
      "193/193 [==============================] - 10631s 55s/step - loss: 0.7923 - masked_accuracy: 0.0691\n",
      "Epoch 3/20\n",
      "193/193 [==============================] - 11619s 60s/step - loss: 0.6517 - masked_accuracy: 0.1404\n",
      "Epoch 4/20\n",
      "193/193 [==============================] - 12649s 66s/step - loss: 0.5625 - masked_accuracy: 0.2296\n",
      "Epoch 5/20\n",
      "193/193 [==============================] - 12709s 66s/step - loss: 0.5010 - masked_accuracy: 0.2796\n",
      "Epoch 6/20\n",
      "193/193 [==============================] - 12702s 66s/step - loss: 0.4533 - masked_accuracy: 0.3229\n",
      "Epoch 7/20\n",
      "193/193 [==============================] - 12757s 66s/step - loss: 0.4140 - masked_accuracy: 0.3605\n",
      "Epoch 8/20\n",
      "193/193 [==============================] - 12832s 66s/step - loss: 0.3785 - masked_accuracy: 0.3964\n",
      "Epoch 9/20\n",
      "193/193 [==============================] - 12824s 66s/step - loss: 0.3447 - masked_accuracy: 0.4329\n",
      "Epoch 10/20\n",
      "193/193 [==============================] - 12932s 67s/step - loss: 0.3106 - masked_accuracy: 0.4709\n",
      "Epoch 11/20\n",
      "193/193 [==============================] - 12787s 66s/step - loss: 0.2766 - masked_accuracy: 0.5136\n",
      "Epoch 12/20\n",
      "193/193 [==============================] - 12927s 67s/step - loss: 0.2415 - masked_accuracy: 0.5604\n",
      "Epoch 13/20\n",
      "193/193 [==============================] - 12865s 67s/step - loss: 0.2057 - masked_accuracy: 0.6130\n",
      "Epoch 14/20\n",
      "193/193 [==============================] - 14129s 73s/step - loss: 0.1741 - masked_accuracy: 0.6617\n",
      "Epoch 15/20\n",
      "193/193 [==============================] - 12793s 66s/step - loss: 0.1464 - masked_accuracy: 0.7085\n",
      "Epoch 16/20\n",
      "193/193 [==============================] - 13170s 68s/step - loss: 0.1276 - masked_accuracy: 0.7350\n",
      "Epoch 17/20\n",
      "193/193 [==============================] - 13145s 68s/step - loss: 0.1129 - masked_accuracy: 0.7605\n",
      "Epoch 18/20\n",
      "193/193 [==============================] - 13444s 70s/step - loss: 0.1007 - masked_accuracy: 0.7798\n",
      "Epoch 19/20\n",
      " 25/193 [==>...........................] - ETA: 3:15:37 - loss: 0.0762 - masked_accuracy: 0.8269"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msample_transformer_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                               \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdecoder_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/transformers/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/transformers/lib/python3.8/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sample_transformer_decoder.fit(x = (encoder_output, decoder_input),\n",
    "                               y = decoder_label,\n",
    "                               epochs = 20,\n",
    "                               verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ad1dc6",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "74b22c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_text = 'कुछ जगहों पर अंग्रेजी शब्दों के हिन्दी अर्थ के रूप में रखे गये हैं'\n",
    "encoder_output_pred = encoder.generate_tokens(hindi_text)\n",
    "\n",
    "english_text = 'At few places english word hindi meaning are kept'\n",
    "decoder_label_pred, decoder_input_pred = decoder_labels_inputs.generate_labels_inputs(english_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "285ec309",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = sample_transformer_decoder([encoder_output_pred, decoder_input_pred], training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "318bcedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 128, 197285), dtype=float32, numpy=\n",
       "array([[[ -9.316858,  -9.341396,  -9.314201, ...,  -9.29075 ,\n",
       "          -9.302386,  -9.311396],\n",
       "        [-11.013479, -10.98209 , -11.04376 , ..., -11.015772,\n",
       "         -10.946828, -11.008596],\n",
       "        [-13.263971, -13.300353, -13.421228, ..., -13.271173,\n",
       "         -13.264562, -13.373016],\n",
       "        ...,\n",
       "        [-14.204481, -14.176577, -14.23652 , ..., -14.224231,\n",
       "         -14.265865, -14.266887],\n",
       "        [-14.167075, -14.140238, -14.201182, ..., -14.184856,\n",
       "         -14.229596, -14.228021],\n",
       "        [-14.186508, -14.158877, -14.224222, ..., -14.203712,\n",
       "         -14.248528, -14.245734]]], dtype=float32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b74376c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_accuracy(pred_label=predictions, decoder_label=decoder_label_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8470e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
